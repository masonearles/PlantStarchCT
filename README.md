# PlantStarchCT
### In-vivo quantification of starch reserves in plant stems using a Random Forest machine learning algorithm

This is the GitHub repository associated with the paper:

Earles, J.M.*, Knipfer, T.K.*, Tixier, A., Orozco, J., Reyes, C., Zwieniecki, M.A., Brodersen, C.R., and McElrone, A.J. (accepted). In-vivo quantification of starch reserves in plants using X-ray microCT imaging and machine learning. *Authors contributed equally

#### Algorithm Description

![Alt text](imgs/Fig_4.png?raw=true "Fig. 4")

Machine learning framework for in-vivo quantification of starch in plant stems. [1.] X-ray microCT images were collected, resulting in 32-bit images of the stem cross section for each plant (n = 12). [2.] Visually empty/full parenchymal regions were manually labeled as full or empty of starch. [3.] Manually labeled images were split equally into test and training image datasets. [4.] MicroCT images were preprocessed (i.e. cropped, denoised, and contrast stretched) to normalize images across plant samples and to facilitate learning by the training algorithm. [5.] Feature layers were generated by convolving the preprocessed images with various types of kernels (e.g. Gaussian, variance, lines, and patches) that corresponded with spatial patterns in X-ray absorption of starch, parenchymal cells, and cell wall tissue. [6.] A random forest algorithm was used to train a model to predict the labeled training images based on available feature layers. [7.] The trained model was used to predict empty/full RAP regions in test images that were not used for training and the modelâ€™s performance was evaluated.

![Alt text](imgs/Fig_1.jpg?raw=true "Fig. 1")

![Alt text](imgs/Fig_3.jpg?raw=true "Fig. 3")

#### The image datasets used in *Earles et al. (accepted)* are several Gb, so we aren't hosting them on GitHub. Please send us a message if you would like a direct link to download them.
